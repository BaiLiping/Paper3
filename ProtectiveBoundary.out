\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Reinforcement Learning For Control Researchers}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Note on Notation and Nomenclature}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{From Dynamic Programming to RL}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.3}{Combine Policy Approximation and Cost-to-go Approximation}{section.2}% 5
\BOOKMARK [3][-]{subsubsection.2.3.1}{Advantage Actor Critic\(A2C\)}{subsection.2.3}% 6
\BOOKMARK [3][-]{subsubsection.2.3.2}{Trust Region Actor Critic}{subsection.2.3}% 7
\BOOKMARK [3][-]{subsubsection.2.3.3}{PPO}{subsection.2.3}% 8
\BOOKMARK [2][-]{subsection.2.4}{Entropy Regularization}{section.2}% 9
\BOOKMARK [1][-]{section.3}{Protective Boundary}{}% 10
\BOOKMARK [2][-]{subsection.3.1}{Protective Boundaries in Atheletic Training}{section.3}% 11
\BOOKMARK [2][-]{subsection.3.2}{Implement Protective Boundary in OpenAI Gym}{section.3}% 12
\BOOKMARK [2][-]{subsection.3.3}{CartPole and Inveretd Pendulum}{section.3}% 13
\BOOKMARK [2][-]{subsection.3.4}{Inverted Double Pendulum}{section.3}% 14
\BOOKMARK [2][-]{subsection.3.5}{Hopper}{section.3}% 15
\BOOKMARK [2][-]{subsection.3.6}{Walker2d}{section.3}% 16
\BOOKMARK [2][-]{subsection.3.7}{HalfCheetah}{section.3}% 17
\BOOKMARK [1][-]{section.4}{Conclution}{}% 18
\BOOKMARK [1][-]{section*.14}{References}{}% 19
